{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T18:51:00.207104Z",
     "start_time": "2024-11-27T18:51:00.194106Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:51:01.077104Z",
     "start_time": "2024-11-27T18:51:00.209104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = [\n",
    "            os.path.join(root, fname)\n",
    "            for fname in os.listdir(root)\n",
    "            if fname.endswith(('jpg', 'png', 'jpeg'))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(\n",
    "        size=224, \n",
    "        scale=(0.85, 1.15),  \n",
    "        ratio=(0.75, 1.33)  \n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = datasets.ImageFolder(\n",
    "    root = 'dl2425_challenge_dataset/train',\n",
    "    transform = transform\n",
    ")\n",
    "valset = datasets.ImageFolder(\n",
    "    root = 'dl2425_challenge_dataset/val',\n",
    "    transform = transform\n",
    ")\n",
    "testset = TestDataset(\n",
    "    root = 'dl2425_challenge_dataset/test',\n",
    "    transform = transform\n",
    ")\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "def init_cnn(module):\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class NandNet(d2l.Classifier):\n",
    "\n",
    "    def __init__(self, numchannels, lr=0.1, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(numchannels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(6), nn.ReLU(),\n",
    "            nn.LazyConv2d(numchannels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LazyBatchNorm2d(6), nn.ReLU(),\n",
    "            nn.LazyConv2d(numchannels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LazyBatchNorm2d(6), nn.ReLU(),\n",
    "            nn.Flatten(), nn.LazyLinear(64), nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(), nn.LazyLinear(16), nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(), nn.LazyLinear(num_classes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "trainer = d2l.Trainer(max_epochs=3, num_gpus=1)\n",
    "model = NandNet(numchannels=6, lr=0.1, num_classes=2)\n",
    "dummy_input = torch.randn(64, 3, 224, 224)  # Batch size = 1, Channels = 3, Height = 224, Width = 224\n",
    "model(dummy_input)\n",
    "model.apply(init_cnn)   \n",
    "data = {\n",
    "    'train_dataloader': trainloader,\n",
    "    'val_dataloader': valloader\n",
    "}\n",
    "trainer.fit(model, data)\n",
    "\n",
    "\n"
   ],
   "id": "cbb433e26b70dab4",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'train_dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 87\u001B[0m\n\u001B[0;32m     82\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(init_cnn)   \n\u001B[0;32m     83\u001B[0m data \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_dataloader\u001B[39m\u001B[38;5;124m'\u001B[39m: trainloader,\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_dataloader\u001B[39m\u001B[38;5;124m'\u001B[39m: valloader\n\u001B[0;32m     86\u001B[0m }\n\u001B[1;32m---> 87\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\d2l\\torch.py:278\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, data)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, data):\n\u001B[1;32m--> 278\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_model(model)\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfigure_optimizers()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\d2l\\torch.py:266\u001B[0m, in \u001B[0;36mTrainer.prepare_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprepare_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m()\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_dataloader \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mval_dataloader()\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_train_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_dataloader)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'dict' object has no attribute 'train_dataloader'"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
