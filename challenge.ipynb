{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10069256,"sourceType":"datasetVersion","datasetId":6206097}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Checking if there is a GPU device available for training. I did the training on Kaggle, so this is just to debug.","metadata":{}},{"cell_type":"code","source":"!pip install d2l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T13:34:54.149120Z","iopub.execute_input":"2024-12-02T13:34:54.149868Z","iopub.status.idle":"2024-12-02T13:35:02.786873Z","shell.execute_reply.started":"2024-12-02T13:34:54.149814Z","shell.execute_reply":"2024-12-02T13:35:02.785768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nprint(\"CUDA Available:\", torch.cuda.is_available())\nprint(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T13:35:02.788624Z","iopub.execute_input":"2024-12-02T13:35:02.788940Z","iopub.status.idle":"2024-12-02T13:35:02.794397Z","shell.execute_reply.started":"2024-12-02T13:35:02.788906Z","shell.execute_reply":"2024-12-02T13:35:02.793554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom d2l import torch as d2l\nimport os\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T13:35:02.795269Z","iopub.execute_input":"2024-12-02T13:35:02.795473Z","iopub.status.idle":"2024-12-02T13:35:02.805070Z","shell.execute_reply.started":"2024-12-02T13:35:02.795451Z","shell.execute_reply":"2024-12-02T13:35:02.804311Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Below I define:\n- A custom Test Dataset class to make the test dataloader\n- The network architecture (to be changed and modified further)\n- A custom Data class to be passed into the trainer.fit() method later","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, root, transform=None):\n        self.root = root\n        self.transform = transform\n        self.image_paths = [\n            os.path.join(root, fname)\n            for fname in os.listdir(root)\n            if fname.endswith(('jpg', 'png', 'jpeg'))\n        ]\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, img_path\n\ndef init_cnn(module):\n    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, nn.LazyConv2d) or isinstance(module, nn.LazyLinear):\n        nn.init.xavier_uniform_(module.weight)\n\nclass NandNet(d2l.Classifier):\n    def __init__(self, numchannels, lr=0.1, num_classes=2):\n        super().__init__()\n        self.save_hyperparameters()\n        self.net = nn.Sequential(\n            nn.LazyConv2d(32, kernel_size=3, stride=1, padding=1),\n            nn.LazyBatchNorm2d(), nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.LazyConv2d(16, kernel_size=3, stride=1, padding=1),\n            nn.LazyBatchNorm2d(), nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.LazyConv2d(9, kernel_size=3, stride=1, padding=1),\n            nn.LazyBatchNorm2d(), nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.LazyConv2d(9, kernel_size=3, stride=1, padding=1),\n            nn.LazyBatchNorm2d(), nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Flatten(), nn.LazyLinear(256), nn.LazyBatchNorm1d(),\n            nn.ReLU(), nn.LazyLinear(64), nn.LazyBatchNorm1d(),\n            nn.ReLU(), nn.LazyLinear(num_classes), nn.Softmax()\n        )\n        \n        self.best_loss = float('inf')\n        self.best_acc = 0\n    \n    def validation_step(self, batch):\n        Y_hat = self(*batch[:-1])\n        l = self.loss(Y_hat, batch[-1])\n        a = self.accuracy(Y_hat, batch[-1])\n        if l < self.best_loss:\n            self.best_loss = l\n        if a > self.best_acc:\n            self.best_acc = a\n        self.plot('loss', l, train=False)\n        self.plot('acc', a, train=False)\n\n        \n\nclass MyData(d2l.DataModule):\n    def __init__(self, batch_size=64):\n        super().__init__()\n        self.save_hyperparameters()\n        self.train = trainset\n        self.val = valset\n        self.batch_size = batch_size\n        \n\n    def text_labels(self, indices):\n        labels = [\"yes\", \"no\"]\n        return [labels[int(i)] for i in indices]\n\n    def get_dataloader(self, train):\n        data = self.train if train else self.val\n        return DataLoader(data, self.batch_size, shuffle=train, num_workers=4)\n\n    def visualize(self, batch, nrows=1, ncols=8, labels=None):\n        if labels is None:\n            labels = []\n        X, y = batch\n        if not labels:\n            labels = self.text_labels(y)\n        d2l.show_images(X.squeeze(1), nrows, ncols, titles=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:09:06.233587Z","iopub.execute_input":"2024-12-02T15:09:06.233962Z","iopub.status.idle":"2024-12-02T15:09:06.248575Z","shell.execute_reply.started":"2024-12-02T15:09:06.233929Z","shell.execute_reply":"2024-12-02T15:09:06.247634Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Below I define:\n- The transformations to apply to our data in order to augment it\n- The variables that hold the training, validation, and test sets","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(\n        size=224,\n        scale=(0.85, 1.15),\n        ratio=(0.75, 1.33)\n    ),\n    transforms.ToTensor(),\n])\n\nkaggle = True\n\ndata_path = '/kaggle/input/kagglechallengedata/dl2425_challenge_dataset' if kaggle else 'dl2425_challenge_dataset'\n\ntrainset = datasets.ImageFolder(\n    root = data_path + '/train',\n    transform = transform\n)\nvalset = datasets.ImageFolder(\n    root = data_path + '/val',\n    transform = transform\n)\ntestset = TestDataset(\n    root = data_path + '/test',\n    transform = transform\n)\n\ntestloader = DataLoader(testset, batch_size=64, shuffle=False)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = NandNet(numchannels=12, lr=0.01, num_classes=2)\n#model.layer_summary((64, 3, 224, 224))\nmodel = model.to(device)\ntrainer = d2l.Trainer(max_epochs=15, num_gpus=4)\ndummy_input = torch.randn(64, 3, 224, 224).to(device)\nmodel(dummy_input)\nmodel.apply(init_cnn)\ndata = MyData(batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:09:11.827883Z","iopub.execute_input":"2024-12-02T15:09:11.828204Z","iopub.status.idle":"2024-12-02T15:09:12.013792Z","shell.execute_reply.started":"2024-12-02T15:09:11.828176Z","shell.execute_reply":"2024-12-02T15:09:12.012882Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Below I define:\n- The code to train the model\n- (If ran in a Jupyter Notebook cell, it also outputs a dynamic train-acc graph)","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    trainer.fit(model, data)\n    print(model.best_loss, model.best_acc)\n    torch.save(model.state_dict(), '4l_var-chnl_256-64_maxpool2_tinylr.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:09:15.019062Z","iopub.execute_input":"2024-12-02T15:09:15.019771Z","iopub.status.idle":"2024-12-02T15:14:49.968992Z","shell.execute_reply.started":"2024-12-02T15:09:15.019737Z","shell.execute_reply":"2024-12-02T15:14:49.967820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Below I define:\n- The model that is to be loaded from the models directory\n- The test loop\n- The results Data Frame which takes multiple dictionaries in the form {id: class} and converts them into cells in a .csv file\n- Saves the predictions.csv file to desired path (this is what we will submit)","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\")\nmodel = NandNet(numchannels=9, lr=0.1, num_classes=2)\ncurrent_model = '/kaggle/working/4l_var-chnl_256-64_maxpool2_tinylr.pth'\nmodel.load_state_dict(torch.load(current_model))\nmodel = model.to(device)\nmodel.eval()\n\nresults = []\n\nwith torch.no_grad():\n    for images, paths in testloader:\n        images = images.to(device)\n        outputs = model(images)\n        \n        probabilities = torch.softmax(outputs, dim=1)\n        predictions = torch.argmax(probabilities, dim=1) \n\n        for path, pred in zip(paths, predictions.cpu().numpy()):\n            filename = os.path.basename(path) \n            results.append({\"id\": filename, \"class\": int(pred)})\n\n# save model predictions!!\nresults = sorted(results, key = lambda x: int(x[\"id\"].replace(\".jpg\", \"\")))\ndf = pd.DataFrame(results)\ndf.to_csv('predictions.csv', index=False)\nprint(\"Predictions saved to 'predictions.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:39:00.266100Z","iopub.execute_input":"2024-12-02T15:39:00.266460Z","iopub.status.idle":"2024-12-02T15:39:16.741009Z","shell.execute_reply.started":"2024-12-02T15:39:00.266426Z","shell.execute_reply":"2024-12-02T15:39:16.740092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Next steps:\n- Make the model better\n- Utilize as few pre made d2l methods as possible\n- Once we are confident in our prediction results, merge (labeled) test, train, and val\n- Train the final model on all of it","metadata":{}}]}