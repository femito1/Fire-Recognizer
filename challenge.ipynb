{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874cf273f867b9aa",
   "metadata": {},
   "source": [
    "Checking if there is a GPU device available for training. I did the training on Kaggle, so this is just to debug."
   ]
  },
  {
   "cell_type": "code",
   "id": "4b62ac99ca15508a",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from d2l import torch as d2l\n",
    "import os\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ecb0bb5157b6e689",
   "metadata": {},
   "source": [
    "## Below I define:\n",
    "- A custom Test Dataset class to make the test dataloader\n",
    "- The network architecture (to be changed and modified further)\n",
    "- A custom Data class to be passed into the trainer.fit() method later"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbb433e26b70dab4",
   "metadata": {},
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = [\n",
    "            os.path.join(root, fname)\n",
    "            for fname in os.listdir(root)\n",
    "            if fname.endswith(('jpg', 'png', 'jpeg'))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "\n",
    "def init_cnn(module):\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class NandNet(d2l.Classifier):\n",
    "\n",
    "    def __init__(self, numchannels, lr=0.1, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(numchannels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.LazyConv2d(numchannels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.LazyConv2d(numchannels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.Flatten(), nn.LazyLinear(64), nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(), nn.LazyLinear(16), nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(), nn.LazyLinear(num_classes)\n",
    "            )\n",
    "\n",
    "class MyData(d2l.DataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.train = trainset\n",
    "        self.val = valset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "\n",
    "    def text_labels(self, indices):\n",
    "        labels = [\"yes\", \"no\"]\n",
    "        return [labels[int(i)] for i in indices]\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        data = self.train if train else self.val\n",
    "        return DataLoader(data, self.batch_size, shuffle=train, num_workers=16)\n",
    "\n",
    "    def visualize(self, batch, nrows=1, ncols=8, labels=None):\n",
    "        if labels is None:\n",
    "            labels = []\n",
    "        X, y = batch\n",
    "        if not labels:\n",
    "            labels = self.text_labels(y)\n",
    "        d2l.show_images(X.squeeze(1), nrows, ncols, titles=labels)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1bcd561c-5b33-49e0-8a54-a622066ce636",
   "metadata": {},
   "source": [
    "## Below I define:\n",
    "- The transformations to apply to our data in order to augment it\n",
    "- THe variables that hold the training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "id": "b80498491e7c09a5",
   "metadata": {},
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(\n",
    "        size=224,\n",
    "        scale=(0.85, 1.15),\n",
    "        ratio=(0.75, 1.33)\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = datasets.ImageFolder(\n",
    "    root = 'dl2425_challenge_dataset/train',\n",
    "    transform = transform\n",
    ")\n",
    "valset = datasets.ImageFolder(\n",
    "    root = 'dl2425_challenge_dataset/val',\n",
    "    transform = transform\n",
    ")\n",
    "testset = TestDataset(\n",
    "    root = 'dl2425_challenge_dataset/test',\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff953511-9d9f-472a-8df8-54a5bc7abca3",
   "metadata": {},
   "source": [
    "## Below I define:\n",
    "- The code to train the model\n",
    "- (If ran in a Jupyter Notebook cell, it also outputs a dynamic train-acc graph)"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e85a6f39e3008a6",
   "metadata": {},
   "source": [
    "\"\"\"if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = NandNet(numchannels=6, lr=0.1, num_classes=2)\n",
    "    model = model.to(device)\n",
    "    trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
    "    dummy_input = torch.randn(64, 3, 224, 224).to(device)\n",
    "    model(dummy_input)\n",
    "    model.apply(init_cnn)\n",
    "    data = MyData(batch_size=64)\n",
    "    trainer.fit(model, data)\n",
    "    torch.save(model.state_dict(), 'model_weights.pth')\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5dfd8ed-e8ed-46b5-a10c-cd9b28772ca2",
   "metadata": {},
   "source": [
    "## Below I define:\n",
    "- The model that is to be loaded from the models directory\n",
    "- The test loop\n",
    "- The results Data Frame which takes multiple dictionaries in the form {id: class} and converts them into cells in a .csv file\n",
    "- Saves the predictions.csv file to desired path (this is what we will submit)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d3328847689df6b",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = NandNet(numchannels=6, lr=0.1, num_classes=2)\n",
    "current_model = 'models/model_weights_3layers_simple.pth'\n",
    "model.load_state_dict(torch.load(current_model))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, paths in testloader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predictions = torch.argmax(probabilities, dim=1) \n",
    "\n",
    "        for path, pred in zip(paths, predictions.cpu().numpy()):\n",
    "            filename = os.path.basename(path) \n",
    "            results.append({\"id\": filename, \"class\": int(pred)})\n",
    "\n",
    "# save model predictions!!\n",
    "results = sorted(results, key = lambda x: int(x[\"id\"].replace(\".jpg\", \"\")))\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'predictions.csv'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "62864869-cb7c-4308-af95-d3754afcd209",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "- Make the model better\n",
    "- Utilize as few premade d2l methods as possible\n",
    "- Once we are confident in our prediction results, merge (labeled) test, train, and val\n",
    "- Train the final model on all of it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
